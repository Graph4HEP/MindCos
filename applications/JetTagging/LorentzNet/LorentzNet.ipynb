{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce27bda0-2fd9-4b01-b866-7597df3f1d82",
   "metadata": {},
   "source": [
    "# LorentzNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14fdcc2d-dd7c-47ec-9407-1ce874979361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] ME(1463391:140183327491904,MainProcess):2024-11-14-11:01:28.904.411 [mindspore/run_check/_check_version.py:219] libcuda.so (need by mindspore-gpu) is not found. Please confirm that libmindspore_gpu.so is in directory:/home/lbz/miniconda3/envs/2030/lib/python3.9/site-packages/mindspore/run_check/../lib/plugin and the correct cuda version has been installed, you can refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[ERROR] ME(1463391:140183327491904,MainProcess):2024-11-14-11:01:28.906.268 [mindspore/run_check/_check_version.py:219] libcudnn.so (need by mindspore-gpu) is not found. Please confirm that libmindspore_gpu.so is in directory:/home/lbz/miniconda3/envs/2030/lib/python3.9/site-packages/mindspore/run_check/../lib/plugin and the correct cuda version has been installed, you can refer to the installation guidelines: https://www.mindspore.cn/install\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported device target GPU. This process only supports one of the ['CPU']. Please check whether the GPU environment is installed and configured correctly, and check whether current mindspore wheel package was built with \"-e GPU\". For details, please refer to \"Device load error message\".\n\n----------------------------------------------------\n- Device load error message:\n----------------------------------------------------\nLoad dynamic library: libmindspore_ascend.so.1 failed. libge_runner.so: cannot open shared object file: No such file or directory\nLoad dynamic library: libmindspore_gpu.so.11.6 failed. libcublas.so.11: cannot open shared object file: No such file or directory\nLoad dynamic library: libmindspore_gpu.so.11.1 failed. libcublas.so.11: cannot open shared object file: No such file or directory\nLoad dynamic library: libmindspore_gpu.so.10.1 failed. libcublas.so.10: cannot open shared object file: No such file or directory\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/core/utils/ms_context.cc:361 SetDeviceTargetFromInner\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmindspore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XavierUniform\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmindspore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m---> 21\u001b[0m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGRAPH_MODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGPU\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/2030/lib/python3.9/site-packages/mindspore/_checkparam.py:1313\u001b[0m, in \u001b[0;36margs_type_check.<locals>.type_check.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, bound_types[name]):\n\u001b[1;32m   1312\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbound_types[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/2030/lib/python3.9/site-packages/mindspore/context.py:1493\u001b[0m, in \u001b[0;36mset_context\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;66;03m# set device target first\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice_target\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m-> 1493\u001b[0m     \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice_target\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m device \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mget_param(ms_ctx_param\u001b[38;5;241m.\u001b[39mdevice_target)\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/2030/lib/python3.9/site-packages/mindspore/context.py:387\u001b[0m, in \u001b[0;36m_Context.set_device_target\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m    385\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReset device target to CPU when set_device_target.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    386\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 387\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mms_ctx_param\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_debug_runtime \u001b[38;5;129;01mand\u001b[39;00m target \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_backend_policy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/2030/lib/python3.9/site-packages/mindspore/context.py:175\u001b[0m, in \u001b[0;36m_Context.set_param\u001b[0;34m(self, param, value)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_param\u001b[39m(\u001b[38;5;28mself\u001b[39m, param, value):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unsupported device target GPU. This process only supports one of the ['CPU']. Please check whether the GPU environment is installed and configured correctly, and check whether current mindspore wheel package was built with \"-e GPU\". For details, please refer to \"Device load error message\".\n\n----------------------------------------------------\n- Device load error message:\n----------------------------------------------------\nLoad dynamic library: libmindspore_ascend.so.1 failed. libge_runner.so: cannot open shared object file: No such file or directory\nLoad dynamic library: libmindspore_gpu.so.11.6 failed. libcublas.so.11: cannot open shared object file: No such file or directory\nLoad dynamic library: libmindspore_gpu.so.11.1 failed. libcublas.so.11: cannot open shared object file: No such file or directory\nLoad dynamic library: libmindspore_gpu.so.10.1 failed. libcublas.so.10: cannot open shared object file: No such file or directory\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/core/utils/ms_context.cc:361 SetDeviceTargetFromInner\n"
     ]
    }
   ],
   "source": [
    "#necessary packages\n",
    "import numpy as np\n",
    "import energyflow\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#mindspore packages\n",
    "import mindspore.dataset as mds\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore as ms\n",
    "from mindspore import Tensor, ops\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Parameter\n",
    "from mindspore.common.initializer import XavierUniform\n",
    "from mindspore import context\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dbb8ef-c890-48e0-9a69-709514af8bec",
   "metadata": {},
   "source": [
    "define the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d2f4e03-5994-429a-896b-8eda800c5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 MindSpore 的数据集类\n",
    "class JetDataset(mds.Dataset):\n",
    "    def __init__(self, label, p4s, nodes, atom_mask, batch_size, repeat_size=1, num_parallel_workers=1):\n",
    "        self.label = label\n",
    "        self.p4s = p4s\n",
    "        self.nodes = nodes\n",
    "        self.atom_mask = atom_mask\n",
    "        self.batch_size = batch_size\n",
    "        self.repeat_size = repeat_size\n",
    "        self.num_parallel_workers = num_parallel_workers\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # 获取单个样本\n",
    "        return (self.label[idx], self.p4s[idx], self.nodes[idx], self.atom_mask[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        # 数据集大小\n",
    "        return len(self.label)\n",
    "\n",
    "    def build(self, column_names=None):\n",
    "        # 构建数据集\n",
    "        ds = mds.NumpySlicesDataset((self.label, self.p4s, self.nodes, self.atom_mask), column_names=['label', 'p4s', 'nodes', 'atom_mask'], sampler=mds.RandomSampler())\n",
    "        # 设置 batch 大小和重复次数\n",
    "        ds = ds.batch(self.batch_size, drop_remainder=True).repeat(self.repeat_size)        \n",
    "        return ds\n",
    "\n",
    "    def map(self):\n",
    "        # 设置并行工作数\n",
    "        ds = self.build()\n",
    "        ds = ds.map(operations=self.collate_fn, input_columns=['label', 'p4s', 'nodes', 'atom_mask'], output_columns=['label', 'p4s', 'nodes', 'atom_mask', 'edge_mask', 'edges'], \n",
    "                    num_parallel_workers=self.num_parallel_workers)\n",
    "        return ds\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(label, p4s, nodes, atom_mask):\n",
    "        # 定义 collate_fn 函数，与 PyTorch中的 collate_fn 类似  \n",
    "        batch_size = p4s.shape[0]\n",
    "        n_nodes = p4s.shape[1]\n",
    "        edge_mask = np.expand_dims(atom_mask, axis=1) * np.expand_dims(atom_mask, axis=2)\n",
    "        diag_mask = np.eye(edge_mask.shape[1], dtype=bool)\n",
    "        diag_mask = ~np.expand_dims(diag_mask, axis=0)\n",
    "        edge_mask *= diag_mask\n",
    "        edges = JetDataset.get_adj_matrix(n_nodes, batch_size, edge_mask)\n",
    "        return label, p4s, nodes, atom_mask, edge_mask, edges\n",
    "\n",
    "    @staticmethod\n",
    "    def get_adj_matrix(n_nodes, batch_size, edge_mask):\n",
    "        # 定义 get_adj_matrix 函数，与 PyTorch 中的 get_adj_matrix 类似\n",
    "        rows, cols = [], []\n",
    "        for batch_idx in range(batch_size):\n",
    "            nn = batch_idx * n_nodes\n",
    "            x = edge_mask[batch_idx]\n",
    "            rows.append(nn + np.where(x)[0])\n",
    "            cols.append(nn + np.where(x)[1])\n",
    "        rows = np.concatenate(rows)\n",
    "        cols = np.concatenate(cols)\n",
    "        return rows, cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303b8d5-f4bf-45ff-9cf2-7345982c3282",
   "metadata": {},
   "source": [
    "define the dataloader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f62922d2-1eb5-4b42-95d3-01e30f0f3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_dataloaders(batch_size, num_data=-1, use_one_hot=True, cache_dir='./data'):\n",
    "    raw = energyflow.qg_jets.load(num_data=num_data, pad=True, ncol=4, generator='pythia',\n",
    "                                  with_bc=False, cache_dir=cache_dir)\n",
    "    splits = ['train', 'val', 'test']\n",
    "    data = {type: {'raw': None, 'label': None} for type in splits}\n",
    "    (data['train']['raw'], data['val']['raw'], data['test']['raw'],\n",
    "     data['train']['label'], data['val']['label'], data['test']['label']) = \\\n",
    "        energyflow.utils.data_split(*raw, train=0.8, val=0.1, test=0.1, shuffle=False)\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore').fit([[11], [13], [22], [130], [211], [321], [2112], [2212]])\n",
    "\n",
    "    for split, value in data.items():\n",
    "        pid = np.abs(np.asarray(value['raw'][..., 3], dtype=int))[..., None]\n",
    "        p4s = energyflow.p4s_from_ptyphipids(value['raw'], error_on_unknown=True)\n",
    "        one_hot = enc.transform(pid.reshape(-1, 1)).toarray().reshape(pid.shape[:2] + (-1,))\n",
    "        one_hot = np.array(one_hot)\n",
    "        mass = energyflow.ms_from_p4s(p4s)[..., None]\n",
    "        charge = energyflow.pids2chrgs(pid)\n",
    "        if use_one_hot:\n",
    "            nodes = one_hot\n",
    "        else:\n",
    "            nodes = np.concatenate((mass, charge), axis=-1)\n",
    "            nodes = np.sign(nodes) * np.log(np.abs(nodes) + 1)\n",
    "        atom_mask = (pid[..., 0] != 0).astype(bool)\n",
    "        value['p4s'] = p4s\n",
    "        value['nodes'] = nodes\n",
    "        value['label'] = value['label']\n",
    "        value['atom_mask'] = atom_mask\n",
    "\n",
    "    datasets = {split: JetDataset(value['label'], value['p4s'], value['nodes'], value['atom_mask'], batch_size)\n",
    "                for split, value in data.items()}\n",
    "\n",
    "    dataloaders = {split: datasets[split].map() for split, dataset in datasets.items()}\n",
    "\n",
    "    return datasets, dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e70f8fd-3bd3-4072-b53d-68665713c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataloaders = retrieve_dataloaders(32, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa3169-db42-44ce-81d8-14a0fa076735",
   "metadata": {},
   "source": [
    "define the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e01cef55-e4de-4389-807b-59d98f03e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGEB(nn.Cell):\n",
    "    def __init__(self, n_input, n_output, n_hidden, n_node_attr=0,\n",
    "                 dropout=0., c_weight=1.0, last_layer=False):\n",
    "        super(LGEB, self).__init__()\n",
    "        self.c_weight = c_weight\n",
    "        n_edge_attr = 2  # dims for Minkowski norm & inner product\n",
    "\n",
    "        # Define the edge feature transformation network (phi_e)\n",
    "        self.phi_e = nn.SequentialCell([\n",
    "            nn.Dense(n_input * 2 + n_edge_attr, n_hidden, has_bias=False),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(n_hidden, n_hidden),\n",
    "            nn.ReLU()\n",
    "        ])\n",
    "\n",
    "        # Define the hidden state transformation network (phi_h)\n",
    "        self.phi_h = nn.SequentialCell([\n",
    "            nn.Dense(n_hidden + n_input + n_node_attr, n_hidden),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(n_hidden, n_output)\n",
    "        ])\n",
    "\n",
    "        # Define the transformation network for x (phi_x)\n",
    "        layer = nn.Dense(n_hidden, 1, has_bias=False, weight_init=XavierUniform(gain=0.001))\n",
    "        self.phi_x = nn.SequentialCell([\n",
    "            nn.Dense(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            layer\n",
    "        ])\n",
    "\n",
    "        # Define the transformation network for m (phi_m)\n",
    "        self.phi_m = nn.SequentialCell([\n",
    "            nn.Dense(n_hidden, 1),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "\n",
    "        self.last_layer = last_layer\n",
    "        if last_layer:\n",
    "            self.phi_x = None\n",
    "\n",
    "    def m_model(self, hi, hj, norms, dots):\n",
    "        out = ops.Concat(axis=1)([hi, hj, norms, dots])\n",
    "        out = self.phi_e(out)\n",
    "        w = self.phi_m(out)\n",
    "        out = out * w\n",
    "        return out\n",
    "\n",
    "    def h_model(self, h, edges, m, node_attr):\n",
    "        i, j = edges\n",
    "        agg = ops.unsorted_segment_sum(m, i, num_segments=h.shape[0])\n",
    "        agg = ops.Concat(axis=1)([h, agg, node_attr])\n",
    "        out = h + self.phi_h(agg)\n",
    "        return out\n",
    "\n",
    "    def x_model(self, x, edges, x_diff, m):\n",
    "        i, j = edges\n",
    "        trans = x_diff * self.phi_x(m)\n",
    "        trans = ops.clamp(trans, min=-100, max=100)\n",
    "        agg = ops.unsorted_segment_sum(trans, i, num_segments=x.shape[0])\n",
    "        x = x + agg * self.c_weight\n",
    "        return x\n",
    "\n",
    "    def minkowski_feats(self, edges, x):\n",
    "        i, j = edges\n",
    "        x_diff = ops.Sub()(x[i], x[j])\n",
    "        norms = self.normsq4(x_diff).view((-1, 1))\n",
    "        dots = self.dotsq4(x[i], x[j]).view((-1, 1))\n",
    "        norms, dots = self.psi(norms), self.psi(dots)\n",
    "        return norms, dots, x_diff\n",
    "\n",
    "    def unsorted_segment_sum(self, data, segment_ids, num_segments):\n",
    "        result = Tensor([0])\n",
    "        result = result.new_zeros((num_segments, data.shape[1]))\n",
    "        result.index_add_(result, segment_ids, data)\n",
    "        return result\n",
    "\n",
    "    def unsorted_segment_mean(self, data, segment_ids, num_segments):\n",
    "        result = Tensor([0])\n",
    "        result = result.new_zeros((num_segments, data.shape[1]))\n",
    "        count = Tensor([0])\n",
    "        count = count.new_zeros((num_segments, data.shape[1]))\n",
    "        result.index_add_(result, segment_ids, data)\n",
    "        count.index_add_(count, segment_ids, Tensor.ones_like(data))\n",
    "        return result / ops.Minimum()(count, Tensor.ones_like(count))\n",
    "    \n",
    "    def normsq4(self, p):\n",
    "        psq = ops.Pow()(p, 2)\n",
    "        return 2 * psq[..., 0] - ops.ReduceSum()(psq, -1)\n",
    "\n",
    "    def dotsq4(self, p, q):\n",
    "        psq = ops.Mul()(p, q)\n",
    "        return 2 * psq[..., 0] - ops.ReduceSum()(psq, -1)\n",
    "    \n",
    "    def psi(self, p):\n",
    "        return ops.Sign()(p) * ops.Log()(ops.Abs()(p) + 1)\n",
    "    \n",
    "    def construct(self, h, x, edges, node_attr=None):\n",
    "        i, j = edges\n",
    "        norms, dots, x_diff = self.minkowski_feats(edges, x)\n",
    "\n",
    "        m = self.m_model(h[i], h[j], norms, dots)  # [B*N, hidden]\n",
    "        if not self.last_layer:\n",
    "            x = self.x_model(x, edges, x_diff, m)\n",
    "        h = self.h_model(h, edges, m, node_attr)\n",
    "        return h, x, m\n",
    "\n",
    "class LorentzNet(nn.Cell):\n",
    "    r''' Implementation of LorentzNet.\n",
    "\n",
    "    Args:\n",
    "        - `n_scalar` (int): number of input scalars.\n",
    "        - `n_hidden` (int): dimension of latent space.\n",
    "        - `n_class`  (int): number of output classes.\n",
    "        - `n_layers` (int): number of LGEB layers.\n",
    "        - `c_weight` (float): weight c in the x_model.\n",
    "        - `dropout`  (float): dropout rate.\n",
    "    '''\n",
    "    def __init__(self, n_scalar, n_hidden, n_class=2, n_layers=6, c_weight=1e-3, dropout=0.1):\n",
    "        super(LorentzNet, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Dense(n_scalar, n_hidden, has_bias=True)\n",
    "        self.LGEBs = nn.CellList([LGEB(self.n_hidden, self.n_hidden, self.n_hidden, \n",
    "                                    n_node_attr=n_scalar, dropout=dropout,\n",
    "                                    c_weight=c_weight, last_layer=(i == n_layers - 1))\n",
    "                                    for i in range(n_layers)])\n",
    "        self.graph_dec = nn.SequentialCell([\n",
    "            nn.Dense(self.n_hidden, self.n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=1-dropout),\n",
    "            nn.Dense(self.n_hidden, n_class)\n",
    "        ])\n",
    "\n",
    "    def construct(self, scalars, x, edges, node_mask, edge_mask, n_nodes):\n",
    "        h = self.embedding(scalars)\n",
    "        #print(h.shape)\n",
    "        for i in range(self.n_layers):\n",
    "            h, x, _ = self.LGEBs[i](h, x, edges, node_attr=scalars)\n",
    "            #print(h.shape, x.shape)\n",
    "\n",
    "        h = ops.Mul()(h, node_mask)\n",
    "        #print(h.shape)\n",
    "        h = ops.Reshape()(h, (-1, n_nodes, self.n_hidden))\n",
    "        #print(h.shape)\n",
    "        h = ops.ReduceMean(keep_dims=False)(h, 1)\n",
    "        #print(h.shape)\n",
    "        pred = self.graph_dec(h)\n",
    "        #print(pred.shape)\n",
    "        return ops.squeeze(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b827a-8f6f-4fdb-8e03-70b328109ef3",
   "metadata": {},
   "source": [
    "initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5f25b5-f873-4348-a696-79cc879b6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LorentzNet(n_scalar = 8, n_hidden = 72, n_class = 2,\n",
    "                       dropout = 0.2, n_layers = 6,\n",
    "                       c_weight = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a5af00-605c-4632-9832-a20a78cd811c",
   "metadata": {},
   "source": [
    "define the optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4bf371-8f81-4284-93c9-a0dac4e593cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nn.optim.AdamW(model.trainable_params(), learning_rate=0.001, weight_decay=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20994a11-c4ba-4493-9779-41b1a0c1ce2d",
   "metadata": {},
   "source": [
    "define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4badc26f-3383-4e0e-8142-5f01ee99e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(nodes, atom_positions, edges, atom_mask, edge_mask, n_nodes, label):\n",
    "    logits = model(scalars=nodes, x=atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                         edge_mask=edge_mask, n_nodes=n_nodes)\n",
    "    loss = loss_fn(logits, label)\n",
    "    return loss, logits\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)\n",
    "\n",
    "def train_loop(model, dataloader):\n",
    "    num_batches = len(dataloader)\n",
    "    model.set_train()\n",
    "    st = 0\n",
    "    total, loss, correct = 0, 0, 0\n",
    "    for i, (label, p4s, nodes, atom_mask, edge_mask, edges) in enumerate(dataloader): \n",
    "        if i == 0:\n",
    "            st = time.time()\n",
    "        label = label.astype(ms.int32)\n",
    "        p4s = p4s.astype(ms.float32)\n",
    "        nodes = nodes.astype(ms.float32)\n",
    "        atom_mask = atom_mask.astype(ms.float32)\n",
    "        edge_mask = edge_mask.astype(ms.float32)\n",
    "        edges = edges.astype(ms.int32)\n",
    "        batch_size, n_nodes, _ = p4s.shape\n",
    "        atom_positions = p4s.reshape(batch_size * n_nodes, -1)\n",
    "        atom_mask = atom_mask.reshape(batch_size * n_nodes, -1)\n",
    "        edge_mask = edge_mask.reshape(batch_size * n_nodes * n_nodes, -1)\n",
    "        nodes = nodes.reshape(batch_size * n_nodes, -1)\n",
    "        (_, logits), grads = grad_fn(nodes, atom_positions, edges, atom_mask, edge_mask, n_nodes, label)        \n",
    "        optimizer(grads)\n",
    "        loss += loss_fn(logits, label).asnumpy()\n",
    "        correct += (logits.argmax(1) == label).asnumpy().sum()\n",
    "        total += len(p4s)\n",
    "        print(f\"loss: {loss/(i+1):>7f} acc: {100*correct/total:>0.1f} [{i:>3d}/{num_batches:>3d}] time: [{time.time()-st:>0.1f}/{(time.time()-st)/(i+1)*num_batches:>0.1f}]\")\n",
    "\n",
    "def test_loop(model, dataloader, loss_fn):\n",
    "    num_batches =len(dataloader)\n",
    "    model.set_train(False)\n",
    "    total, test_loss, correct = 0, 0, 0\n",
    "    for i, (label, p4s, nodes, atom_mask, edge_mask, edges) in enumerate(dataloader): \n",
    "        label = label.astype(ms.int32)\n",
    "        p4s = p4s.astype(ms.float32)\n",
    "        nodes = nodes.astype(ms.float32)\n",
    "        atom_mask = atom_mask.astype(ms.float32)\n",
    "        edge_mask = edge_mask.astype(ms.float32)\n",
    "        edges = edges.astype(ms.int32)\n",
    "        batch_size, n_nodes, _ = p4s.shape\n",
    "        atom_positions = p4s.reshape(batch_size * n_nodes, -1)\n",
    "        atom_mask = atom_mask.reshape(batch_size * n_nodes, -1)\n",
    "        edge_mask = edge_mask.reshape(batch_size * n_nodes * n_nodes, -1)\n",
    "        nodes = nodes.reshape(batch_size * n_nodes, -1)\n",
    "        pred = model(scalars=nodes, x=atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                         edge_mask=edge_mask, n_nodes=n_nodes)\n",
    "        total += len(p4s)\n",
    "        test_loss += loss_fn(pred, label).asnumpy()\n",
    "        correct += (pred.argmax(1) == label).asnumpy().sum()\n",
    "    test_loss /= num_batches\n",
    "    correct /= total\n",
    "    print(f\"Valid: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722789cb-afb3-469d-b81f-49e6b9367a62",
   "metadata": {},
   "source": [
    "start train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce879e3e-e4bb-4cd7-a5bf-c296d142a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.716955 acc: 46.9 [  0/ 25] time: [3.9/98.3]\n",
      "loss: 0.328701 acc: 75.0 [  1/ 25] time: [6.8/85.6]\n",
      "loss: 0.209071 acc: 68.8 [  2/ 25] time: [8.8/73.2]\n",
      "loss: 0.173809 acc: 50.0 [  3/ 25] time: [10.1/63.2]\n",
      "loss: 0.154643 acc: 37.5 [  4/ 25] time: [11.2/55.9]\n",
      "loss: 0.119221 acc: 65.6 [  5/ 25] time: [12.6/52.6]\n",
      "loss: 0.094338 acc: 65.6 [  6/ 25] time: [14.0/49.9]\n",
      "loss: 0.071432 acc: 65.6 [  7/ 25] time: [15.3/47.8]\n",
      "loss: 0.081528 acc: 56.2 [  8/ 25] time: [16.8/46.7]\n",
      "loss: 0.055734 acc: 65.6 [  9/ 25] time: [18.1/45.3]\n",
      "loss: 0.057421 acc: 40.6 [ 10/ 25] time: [19.1/43.4]\n",
      "loss: 0.048941 acc: 81.2 [ 11/ 25] time: [20.2/42.1]\n",
      "loss: 0.045201 acc: 68.8 [ 12/ 25] time: [21.8/41.9]\n",
      "loss: 0.046636 acc: 71.9 [ 13/ 25] time: [23.2/41.4]\n",
      "loss: 0.036176 acc: 68.8 [ 14/ 25] time: [25.0/41.7]\n",
      "loss: 0.041269 acc: 68.8 [ 15/ 25] time: [26.3/41.1]\n",
      "loss: 0.046727 acc: 56.2 [ 16/ 25] time: [27.2/40.1]\n",
      "loss: 0.037071 acc: 68.8 [ 17/ 25] time: [28.6/39.8]\n",
      "loss: 0.034051 acc: 71.9 [ 18/ 25] time: [29.8/39.2]\n",
      "loss: 0.028975 acc: 62.5 [ 19/ 25] time: [31.1/38.9]\n",
      "loss: 0.027447 acc: 68.8 [ 20/ 25] time: [32.4/38.6]\n",
      "loss: 0.030043 acc: 62.5 [ 21/ 25] time: [33.9/38.6]\n",
      "loss: 0.024368 acc: 75.0 [ 22/ 25] time: [35.4/38.5]\n",
      "loss: 0.028251 acc: 75.0 [ 23/ 25] time: [36.6/38.1]\n",
      "loss: 0.023742 acc: 68.8 [ 24/ 25] time: [37.9/37.9]\n",
      "\n",
      "Valid: \n",
      " Accuracy: 60.4%, Avg loss: 0.679158 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.559596 acc: 68.8 [  0/ 25] time: [1.6/41.2]\n",
      "loss: 0.270572 acc: 75.0 [  1/ 25] time: [2.8/34.8]\n",
      "loss: 0.169649 acc: 75.0 [  2/ 25] time: [4.1/33.8]\n",
      "loss: 0.142148 acc: 78.1 [  3/ 25] time: [5.4/34.0]\n",
      "loss: 0.097771 acc: 71.9 [  4/ 25] time: [6.9/34.3]\n",
      "loss: 0.088238 acc: 78.1 [  5/ 25] time: [8.1/33.9]\n",
      "loss: 0.086546 acc: 81.2 [  6/ 25] time: [9.5/33.8]\n",
      "loss: 0.051839 acc: 90.6 [  7/ 25] time: [10.6/33.3]\n",
      "loss: 0.086225 acc: 62.5 [  8/ 25] time: [12.0/33.5]\n",
      "loss: 0.069365 acc: 71.9 [  9/ 25] time: [13.4/33.5]\n",
      "loss: 0.044175 acc: 84.4 [ 10/ 25] time: [14.4/32.6]\n",
      "loss: 0.046035 acc: 84.4 [ 11/ 25] time: [15.6/32.5]\n",
      "loss: 0.051908 acc: 65.6 [ 12/ 25] time: [16.7/32.2]\n",
      "loss: 0.031418 acc: 84.4 [ 13/ 25] time: [18.2/32.5]\n",
      "loss: 0.049289 acc: 65.6 [ 14/ 25] time: [19.2/32.0]\n",
      "loss: 0.042634 acc: 75.0 [ 15/ 25] time: [20.7/32.4]\n",
      "loss: 0.035334 acc: 65.6 [ 16/ 25] time: [22.1/32.4]\n",
      "loss: 0.036317 acc: 71.9 [ 17/ 25] time: [23.3/32.3]\n",
      "loss: 0.025581 acc: 90.6 [ 18/ 25] time: [24.6/32.4]\n",
      "loss: 0.033400 acc: 68.8 [ 19/ 25] time: [26.1/32.6]\n",
      "loss: 0.022514 acc: 84.4 [ 20/ 25] time: [27.5/32.8]\n",
      "loss: 0.030092 acc: 59.4 [ 21/ 25] time: [28.7/32.6]\n",
      "loss: 0.033481 acc: 65.6 [ 22/ 25] time: [30.0/32.6]\n",
      "loss: 0.026454 acc: 75.0 [ 23/ 25] time: [31.4/32.7]\n",
      "loss: 0.020110 acc: 78.1 [ 24/ 25] time: [32.9/32.9]\n",
      "\n",
      "Valid: \n",
      " Accuracy: 71.9%, Avg loss: 0.560858 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.610840 acc: 62.5 [  0/ 25] time: [1.3/33.6]\n",
      "loss: 0.300956 acc: 71.9 [  1/ 25] time: [2.4/29.6]\n",
      "loss: 0.213515 acc: 65.6 [  2/ 25] time: [3.5/29.4]\n",
      "loss: 0.146571 acc: 71.9 [  3/ 25] time: [4.9/30.6]\n",
      "loss: 0.119905 acc: 68.8 [  4/ 25] time: [6.2/31.2]\n",
      "loss: 0.093900 acc: 78.1 [  5/ 25] time: [7.4/30.9]\n",
      "loss: 0.079275 acc: 84.4 [  6/ 25] time: [8.5/30.3]\n",
      "loss: 0.069196 acc: 78.1 [  7/ 25] time: [10.1/31.6]\n",
      "loss: 0.057607 acc: 87.5 [  8/ 25] time: [11.4/31.6]\n",
      "loss: 0.059468 acc: 75.0 [  9/ 25] time: [12.7/31.7]\n",
      "loss: 0.047940 acc: 78.1 [ 10/ 25] time: [14.0/31.7]\n",
      "loss: 0.051718 acc: 78.1 [ 11/ 25] time: [15.4/32.0]\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "for t in range(10):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(model, dataloaders['train'])\n",
    "    print()\n",
    "    test_loop(model, dataloaders['val'], loss_fn)\n",
    "\n",
    "print('Test')\n",
    "test_loop(model, dataloaders['test'], loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a258083-2043-448b-ad23-5c5d7b11820c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dcc49d-51ae-42bf-9014-0d334d05b321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4dcd42-198d-4bc3-962c-1d368aea3aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbf651-b0a5-4c23-b79f-48f6763eff1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229a712-adca-41ee-9d90-86d7c35859ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad24e93f-b082-4e87-96fa-d22ba97db850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6d7eb-1a0f-4c9a-84a9-5aa1da583780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946b44a-8982-4039-ad91-cffad0a4b85c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2030",
   "language": "python",
   "name": "2030"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
